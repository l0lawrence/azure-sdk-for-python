# coding=utf-8
# --------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License. See License.txt in the project root for license information.
# Code generated by Microsoft (R) AutoRest Code Generator.
# Changes may cause incorrect behavior and will be lost if the code is regenerated.
# --------------------------------------------------------------------------

import datetime
from enum import Enum
from typing import Any, Dict, List, Optional, Union, get_type_hints, get_origin, get_args, cast
from typing_extensions import TypedDict, Required, NotRequired, is_typeddict
from azure.core import CaseInsensitiveEnumMeta

from .models import ResourceType


# --------------------------------------------------------------------------
# Runtime TypedDict validation helpers
# --------------------------------------------------------------------------

def _parse_datetime_string(value: Any) -> Optional[Union[str,datetime.datetime]]:
    """Parse datetime from ISO string."""
    if value is None or isinstance(value, datetime.datetime):
        return value
    if isinstance(value, str):
        try:
            return datetime.datetime.fromisoformat(value.replace("Z", "+00:00"))
        except Exception:
            return value
    return value


def _parse_enum_value(value: Any, enum_cls: type) -> Any:
    """Parse enum value from string."""
    if value is None or isinstance(value, enum_cls):
        return value
    if isinstance(value, str) and issubclass(enum_cls, Enum):
        try:
            return enum_cls(value)
        except (ValueError, KeyError):
            try:
                return enum_cls[value]
            except (ValueError, KeyError):
                return value
    return value


def _validate_typeddict_field(value: Any, field_type: type) -> Any:
    """Validate and transform a field value based on its type hint."""
    origin = get_origin(field_type)
    args = get_args(field_type)
    
    # Handle Optional[T] -> Union[T, None]
    if origin is Union:
        # Check if this is Optional (Union with None)
        if len(args) == 2 and type(None) in args:
            if value is None:
                return None
            # Get the non-None type
            inner_type = next(arg for arg in args if arg is not type(None))
            return _validate_typeddict_field(value, inner_type)
        else:
            # Regular Union - try each type
            for arg in args:
                try:
                    return _validate_typeddict_field(value, arg)
                except Exception:
                    continue
            return value
    
    # Handle List[T]
    elif origin is list or origin is List:
        if not isinstance(value, list):
            return value
        if args:
            item_type = args[0]
            return [_validate_typeddict_field(item, item_type) for item in value]
        return value
    
    # Handle Dict[K, V]
    elif origin is dict or origin is Dict:
        if not isinstance(value, dict):
            return value
        if len(args) >= 2:
            key_type, value_type = args[0], args[1]
            return {
                _validate_typeddict_field(k, key_type): _validate_typeddict_field(v, value_type)
                for k, v in value.items()
            }
        return value
    
    # Handle TypedDict
    elif is_typeddict(field_type):
        return _create_runtime_typeddict_instance(value, field_type)
    
    # Handle Enum
    elif isinstance(field_type, type) and issubclass(field_type, Enum):
        return _parse_enum_value(value, field_type)
    
    # Handle datetime
    elif field_type is datetime.datetime:
        return _parse_datetime_string(value)
    
    # Handle basic types
    elif field_type in (str, int, float, bool):
        if value is None:
            return None
        try:
            return field_type(value)
        except (ValueError, TypeError):
            return value
    
    # Return as-is for unknown types
    return value


def _snake_to_camel(snake_str: str) -> str:
    """Convert snake_case to camelCase."""
    components = snake_str.split('_')
    return components[0] + ''.join(x.title() for x in components[1:])


def _camel_to_snake(camel_str: str) -> str:
    """Convert camelCase to snake_case."""
    result = []
    for i, char in enumerate(camel_str):
        if char.isupper() and i > 0:
            result.append('_')
        result.append(char.lower())
    return ''.join(result)


def _validate_typeddict_properties(data: Any, typeddict_class: type) -> Dict[str, Any]:
    """Validate and transform data according to a TypedDict schema.
    
    Maps camelCase keys from service response to snake_case TypedDict fields.
    """
    if not isinstance(data, dict):
        data = data or {}
    
    hints = get_type_hints(typeddict_class, include_extras=True)
    result = {}
    
    for field_name, field_type in hints.items():
        # Try snake_case first, then camelCase
        camel_name = _snake_to_camel(field_name)
        if field_name in data:
            result[field_name] = _validate_typeddict_field(data[field_name], field_type)
        elif camel_name in data:
            result[field_name] = _validate_typeddict_field(data[camel_name], field_type)
        else:
            # Check if field is required (not Optional and not NotRequired)
            origin = get_origin(field_type)
            if origin is Union:
                args = get_args(field_type)
                if len(args) == 2 and type(None) in args:
                    # Optional field
                    result[field_name] = None
            # For NotRequired fields, we don't set them if missing
    
    # Include any extra fields that aren't in the TypedDict (keep original keys)
    for key, value in data.items():
        snake_key = _camel_to_snake(key)
        if key not in hints and snake_key not in hints:
            result[key] = value
    
    return result


def _create_runtime_typeddict_instance(data: Any, typeddict_class: type):
    """Create a runtime instance that behaves like the TypedDict class.
    
    Maps camelCase service response keys to snake_case TypedDict keys.
    Returns a dict-like object that preserves TypedDict type information.
    """
    validated_data = _validate_typeddict_properties(data, typeddict_class)
    
    # Create a custom dict subclass that identifies as the TypedDict for type checking
    class TypedDictInstance(dict):
        __annotations__ = getattr(typeddict_class, '__annotations__', {})
        
        def __repr__(self):
            return f"{typeddict_class.__name__}({dict.__repr__(self)})"
    
    # Set class metadata to match the TypedDict
    TypedDictInstance.__name__ = typeddict_class.__name__
    TypedDictInstance.__module__ = getattr(typeddict_class, '__module__', __name__)
    
    # Create and return the instance
    return TypedDictInstance(validated_data)


class AccountImmutabilityPolicyState(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The ImmutabilityPolicy state defines the mode of the policy. Disabled state disables the
    policy, Unlocked state allows increase and decrease of immutability retention time and also
    allows toggling allowProtectedAppendWrites property, Locked state only allows the increase of
    the immutability retention time. A policy can only be created in a Disabled or Unlocked state
    and can be toggled between the two states. Only a policy in an Unlocked state can transition to
    a Locked state which cannot be reverted.
    """

    UNLOCKED = "Unlocked"
    LOCKED = "Locked"
    DISABLED = "Disabled"

class ImmutabilityPolicyProperties(TypedDict):
    """Properties of an Immutability Policy."""
    immutability_period_since_creation_in_days: Optional[int]
    state: Optional[Union[str,AccountImmutabilityPolicyState]]
    allow_protected_append_writes: Optional[bool]

class TagProperty(TypedDict):
    """Tag property of a Legal Hold."""
    tag: Optional[str]
    timestamp: Optional[datetime.datetime]
    object_identifier: Optional[str]
    tenant_id: Optional[str]
    upn: Optional[str]

class ProtectedAppendWritesHistory(TypedDict):
    """Protected append writes history."""
    allow_protected_append_writes_all: Optional[bool]
    timestamp: Optional[datetime.datetime]

class LegalHoldProperties(TypedDict):
    """Properties of a Legal Hold."""
    has_legal_hold: Optional[bool]
    tags: Optional[List[TagProperty]]
    protected_append_writes_history: Optional[ProtectedAppendWritesHistory]

class MigrationState(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """This property denotes the container level immutability to object level immutability migration
    state.
    """

    IN_PROGRESS = "InProgress"
    COMPLETED = "Completed"

class ImmutableStorageWithVersioning(TypedDict):
    """Immutable storage with versioning properties."""
    enabled: Optional[bool]
    time_stamp: Optional[datetime.datetime]
    migration_state: Optional[Union[str, MigrationState]]


class BlobContainerProperties(TypedDict):
    """Properties of a Blob Container resource."""
    public_access: NotRequired[Optional[str]]
    last_modified_time: NotRequired[Optional[str]]
    etag: NotRequired[Optional[str]]
    version: NotRequired[Optional[str]]
    deleted: NotRequired[Optional[bool]]
    deleted_time: NotRequired[Optional[str]]
    remaining_retention_days: NotRequired[Optional[int]]
    default_encryption_scope: NotRequired[Optional[str]]
    deny_encryption_scope_override: NotRequired[Optional[bool]]
    lease_status: NotRequired[Optional[str]]
    lease_state: NotRequired[Optional[str]]
    lease_duration: NotRequired[Optional[str]]
    metadata: NotRequired[Optional[Dict[str, str]]]
    immutability_policy: NotRequired[Optional[ImmutabilityPolicyProperties]]
    legal_hold: NotRequired[Optional[LegalHoldProperties]]
    has_legal_hold: NotRequired[Optional[bool]]
    has_immutability_policy: NotRequired[Optional[bool]]
    immutable_storage_with_versioning: NotRequired[Optional[ImmutableStorageWithVersioning]]
    enable_nfs_v3_root_squash: NotRequired[Optional[bool]]
    enable_nfs_v3_all_squash: NotRequired[Optional[bool]]


class BlobContainerPathParams(TypedDict):
    """URL parameters required to address a blob container."""

    resource_group_name: str
    storage_account_name: str
    container_name: Optional[str] # optional because not needed for list operation


class BlobContainer(ResourceType[BlobContainerProperties, BlobContainerPathParams]):

    """A Blob Container resource."""

    _read_url_template = (
        "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/"
        "providers/Microsoft.Storage/storageAccounts/{storageAccountName}/"
        "blobServices/default/containers/{containerName}"
    )

    _create_url_template = (
        "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/"
        "providers/Microsoft.Storage/storageAccounts/{storageAccountName}/"
        "blobServices/default/containers/{containerName}"
    )

    
    @classmethod
    def get_operation_url(
        cls,
        operation: str,
        subscription_id: str,
        url_params: BlobContainerPathParams,
    ) -> str:
        if operation == "read":
            return cls._read_url_template.format(
                subscriptionId=subscription_id,
                resourceGroupName=url_params["resource_group_name"],
                storageAccountName=url_params["storage_account_name"],
                containerName=url_params["container_name"],
            )
        elif operation == "create":
            return cls._create_url_template.format(
                subscriptionId=subscription_id,
                resourceGroupName=url_params["resource_group_name"],
                storageAccountName=url_params["storage_account_name"],
                containerName=url_params["container_name"],
            )
        raise ValueError(f"Unsupported operation '{operation}' for {cls.__name__}")
    
    @classmethod
    def from_response(cls, data_dict: Dict[str, Any], **kwargs) -> "BlobContainer":
        properties = _create_runtime_typeddict_instance(
            data_dict.get("properties", {}), BlobContainerProperties
        )

        instance = cls(
            api_version=kwargs.get("api_version", "2025-06-01"),
            properties=properties,  
        )

        instance.id = data_dict.get("id")
        instance.name = data_dict.get("name")
        instance.type = data_dict.get("type")

        return instance

    def __init__(
        self,
        *,
        api_version: str = "2025-06-01",
        properties: Optional[BlobContainerProperties] = None,
        **kwargs: Any,
    ) -> None:
        super().__init__(**kwargs)
        self.api_version = api_version
        self.properties = properties
        

    def to_dict(self) -> Dict[str, Any]:
        # Serialize container properties for create/update requests
        return {
            "properties": self.properties,
        }

    @classmethod
    def build_instance_path_arguments_from_params(
        cls,
        *,
        subscription_id: str,
        url_params: BlobContainerPathParams,
    ) -> Dict[str, Any]:
        """Build path arguments dictionary from URL parameters.

        Base resources only use subscription ID. Subclasses should override when
        they need additional path arguments.

        :param subscription_id: Subscription identifier.
        :param url_params: URL parameters required by the resource type.
        :return: Dictionary of path arguments.
        """
        if url_params.get("container_name") is None:
            dict_to_return = {
                "subscriptionId": subscription_id,
                "resourceGroupName": url_params["resource_group_name"],
                "storageAccountName": url_params["storage_account_name"],
            }
        else:
            dict_to_return = {
                "subscriptionId": subscription_id,
                "resourceGroupName": url_params["resource_group_name"],
                "storageAccountName": url_params["storage_account_name"],
                "containerName": cast(str, url_params["container_name"]),
            }
        return dict_to_return